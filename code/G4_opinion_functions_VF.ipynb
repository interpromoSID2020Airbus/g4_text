{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Thu Jan 14 11:00:00 2020\\nGroup 4\\n@author : FR , CBO, JC, N\\nLearning\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Thu Jan 14 11:00:00 2020\n",
    "Group 4\n",
    "Sub Group : Opinion\n",
    "@author : FR , CBO, JC, NM\n",
    "Learning \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU, LSTM, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import SpatialDropout1D, Dropout, Bidirectional, Conv1D, GlobalMaxPooling1D, MaxPooling1D, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import estimate_bandwidth\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(file):\n",
    "    data = pd.read_csv(\"../data/\"+file+\".csv\", sep=',', index_col=0)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html?highlight=gaussian%20nb#sklearn.naive_bayes.GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_NB(X_train, y_train, X_test, priors):\n",
    "    '''\n",
    "    Documentation :\n",
    "    Parameters : \n",
    "        X_train : Training data\n",
    "        y_train : label of training data\n",
    "        X_test : Data test\n",
    "        priors : Prior probabilities of the classes\n",
    "    Output : \n",
    "        predict of data test\n",
    "    '''\n",
    "    gnb = GaussianNB(priors=priors).fit(X_train, y_train.astype(int))\n",
    "    return (gnb.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=random%20forest#sklearn.ensemble.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest(X_train, y_train, X_test, n_estimator, max_depth):\n",
    "    '''\n",
    "    Documentation :\n",
    "    Parameters : \n",
    "        X_train : Training data\n",
    "        y_train : label of training data\n",
    "        X_test : Data test\n",
    "        n_estimator : The number of trees in the forest.\n",
    "        max_depth : The maximum depth of the tree.\n",
    "    Output : \n",
    "        predict of data test\n",
    "    '''\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimator, max_depth=max_depth)\n",
    "    clf.fit(X_train, y_train.astype(int))\n",
    "    return (clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regression#sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_Regression(X_train, y_train, X_test, penalty='l2', solver='lbfgs', multi_class='auto', max_iter=100):\n",
    "    '''\n",
    "    Documentation :\n",
    "    Parameters :\n",
    "        X_train : Training data\n",
    "        y_train : label of training data\n",
    "        X_test : Data test\n",
    "        penalty : Used to specify the norm used in the penalization.\n",
    "        solver : Algorithm to use in the optimization problem.\n",
    "        {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "        max_iter : Maximum number of iterations taken for the solvers to converge.\n",
    "    Output :\n",
    "        predict of data test\n",
    "    '''\n",
    "    clf = LogisticRegression(penalty=penalty, solver=solver, multi_class=multi_class, max_iter=max_iter)\n",
    "    clf.fit(X_train, y_train.astype(int))\n",
    "    return (clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDClassifier\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html?highlight=sgd%20classifier#sklearn.linear_model.SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(X_train, y_train, X_test, loss, penalty):\n",
    "    '''\n",
    "    Documentation :\n",
    "    Parameters :\n",
    "        X_train : Training data\n",
    "        y_train : label of training data\n",
    "        X_test : Data test\n",
    "        loss : The loss function to be used\n",
    "        penalty :The penalty to be used\n",
    "    Output :\n",
    "        predict of data test\n",
    "    '''\n",
    "    clf = SGDClassifier(loss=loss, penalty=penalty)\n",
    "    clf.fit(X_train, y_train.astype(int))\n",
    "    return (clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Metric\n",
    "F mesure: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html?highlight=f1%20score#sklearn.metrics.f1_score\n",
    "Accuracy: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html?highlight=accuracy#sklearn.metrics.accuracy_score\n",
    "Confusion matrix: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html?highlight=confusion_matrix#sklearn.metrics.confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Classification_Metric(y_pred, y_test):\n",
    "    '''\n",
    "    Documentation :\n",
    "    Parameters :\n",
    "        y_pred : label predict\n",
    "        y_test : true label\n",
    "    Output :\n",
    "        Score : F mesure, Accuracy and confusion matrix\n",
    "    '''\n",
    "    F1_score = sklearn.metrics.f1_score(y_test, y_pred, labels=None, pos_label=1, average='micro', sample_weight=None)\n",
    "    Accuracy_score = sklearn.metrics.accuracy_score(y_test, y_pred, normalize=True, sample_weight=None)\n",
    "    Confusion_matrix = sklearn.metrics.confusion_matrix(y_test, y_pred, labels=None, sample_weight=None)\n",
    "    return('F mesure', F1_score, 'Accuracy', Accuracy_score, 'Confusion Matrix', Confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  K-nearest neighbors \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html?highlight=kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_neighbors_classifier(X_train, y_train, X_test, n_neighbors) :\n",
    "    \n",
    "    '''\n",
    "    Documentation :\n",
    "    Parameters : \n",
    "        df_tf_idf : Training data\n",
    "        y_train : label of training data\n",
    "        n_neighbors : Number of neighbors to use by default for kneighbors queries\n",
    "\n",
    "    Output : \n",
    "        predict of data test\n",
    "    '''\n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    return(neigh.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Means \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html?highlight=kmeans#sklearn.cluster.KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_Means(X_train, n_cluster, max_iter, n_init):\n",
    "    '''\n",
    "    Documentation :\n",
    "    Parameters :\n",
    "        X_train : Training data\n",
    "        n_cluster : Number of cluster\n",
    "        n_init : Method for initialization\n",
    "    Output :\n",
    "        predict of data test\n",
    "    '''\n",
    "    model = KMeans(n_clusters=n_cluster).fit(X_train)\n",
    "    return(model.labels_ - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Mixture\n",
    "https://scikit-learn.org/stable/modules/mixture.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mixture(X_train, n_components=3) :\n",
    "    '''\n",
    "    Documentation :\n",
    "    Parameters : \n",
    "        df_tf_idf : Training data\n",
    "        n_components : The number of mixture components\n",
    "    Output : \n",
    "        predict of data test\n",
    "    '''\n",
    "    gmm = GaussianMixture(n_components=n_components).fit(X_train)\n",
    "    return(gmm.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affinity propagation\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.affinity_propagation.html?highlight=affinity_propagation#sklearn.cluster.affinity_propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinity_propagation(X_train) :\n",
    "    \n",
    "    '''\n",
    "    Documentation :\n",
    "    Parameters : \n",
    "        df_tf_idf : Training data\n",
    "    Output : \n",
    "        predict of data test\n",
    "    '''\n",
    "    \n",
    "    clustering = AffinityPropagation().fit(X_train)\n",
    "    return(clustering.labels_ - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agglomerative Clustering\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html?highlight=agglomerative%20clustering#sklearn.cluster.AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglomerative_clustering(X_train, n_clusters=3, affinity='euclidean' ):\n",
    "    \n",
    "    '''\n",
    "    Documentation :\n",
    "    Parameters : \n",
    "        df_tf_idf : Training data\n",
    "        \n",
    "    Output : \n",
    "        predict of data test\n",
    "    '''\n",
    "\n",
    "    clustering = AgglomerativeClustering(n_clusters=n_clusters, affinity=affinity).fit(X_train)\n",
    "    return(clustering.labels_ - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Shift\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.mean_shift.html?highlight=mean%20shift#sklearn.cluster.mean_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_shift(X_train, bin_seeding):\n",
    "    \n",
    "    '''\n",
    "    Documentation :\n",
    "    Parameters : \n",
    "        df_tf_idf : Training data\n",
    "        bandwidth : Used in the RBF kernel.\n",
    "        bin_seeding : If true initial kernel locations are not locations of all points\n",
    "        \n",
    "    Output : \n",
    "        predict of data test\n",
    "    '''\n",
    "\n",
    "    bandwidth = estimate_bandwidth(X_train, quantile=0.2, n_samples=100)\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=bin_seeding).fit(X_train)\n",
    "    return(ms.labels_ - 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DB Scan\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.mean_shift.html?highlight=mean%20shift#sklearn.cluster.mean_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_scan(X_train, eps, min_samples, n_jobs):\n",
    "    \n",
    "    '''\n",
    "    Documentation :\n",
    "    Parameters : \n",
    "        df_tf_idf : Training data\n",
    "        eps : The maximum distance between two samples for one to be considered as in the neighborhood of the other\n",
    "        min_samples : The number of samples in a neighborhood for a point to be considered as a core point\n",
    "        n_jobs : The number of parallel jobs to run\n",
    "        \n",
    "    Output : \n",
    "        predict of data test\n",
    "    '''\n",
    "    \n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples, n_jobs=n_jobs).fit(X_train)\n",
    "    return(clustering.labels_ - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silouhette_score_KMeans(nb_clusters: int, X_train):\n",
    "    '''\n",
    "    Documentation:\n",
    "    Parameters:\n",
    "        nb_cluster: number of cluster\n",
    "        matrix_tfidf: Tf idf\n",
    "    Output:\n",
    "        Score: Silouhette\n",
    "    '''\n",
    "    res = np.arange(nb_clusters, dtype=\"double\")\n",
    "    for k in np.arange(nb_clusters):\n",
    "        clusters = KMeans(n_clusters=k+2).fit(X_train)\n",
    "        res[k] = metrics.silhouette_score(X_train, clusters.labels_)\n",
    "    # graph\n",
    "    plt.title(\"Silhouette\")\n",
    "    plt.plot(np.arange(2, nb_clusters + 2, 1), res)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_score(y_true, y_pred):\n",
    "    '''\n",
    "    Documentation:\n",
    "    compute contingency matrix also called confusion matrix\n",
    "    Parameters:\n",
    "        y_pred: label predict\n",
    "        y_test: true label\n",
    "    Output:\n",
    "        Score: Purity\n",
    "    '''\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/models/about-keras-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GruCNN(X_train, y_train, X_test, y_test, data_to_predict, max_features=10000, max_words=120, batch_size=128, epochs=4, num_classes=3):\n",
    "    \"\"\"\n",
    "    Documentation\n",
    "\n",
    "    Parameters:\n",
    "        max_features: the number of rows to take in input\n",
    "        max_words: the maximum amout of words that will be encoded for one row\n",
    "        batch_size: number of training examples utilized in one iteration\n",
    "        epochs: number of iterations\n",
    "        num_classes: number of labels to predict\n",
    "\n",
    "    Output:\n",
    "        y_pred7: prediction of y_test by the trained model\n",
    "    \"\"\"\n",
    "    model7_GruCNN = Sequential()\n",
    "    model7_GruCNN.add(Embedding(max_features, 100, input_length=max_words))\n",
    "    model7_GruCNN.add(Dropout(0.2))\n",
    "    model7_GruCNN.add(Bidirectional(GRU(units=128, return_sequences=True)))\n",
    "    model7_GruCNN.add(Conv1D(32, kernel_size=3, padding='same', activation='relu'))\n",
    "    model7_GruCNN.add(GlobalMaxPooling1D())\n",
    "    model7_GruCNN.add(Dense(units=64, activation='relu'))\n",
    "    model7_GruCNN.add(Dropout(0.5))\n",
    "    model7_GruCNN.add(Dense(units=3, activation='softmax'))\n",
    "    model7_GruCNN.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam', metrics=['accuracy'])\n",
    "    model7_GruCNN.summary()\n",
    "    history7 = model7_GruCNN.fit(X_train, y_train, validation_data=(\n",
    "        X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "    y_pred = model7_GruCNN.predict_classes(data_to_predict, verbose=1)\n",
    "    return pd.Series(y_pred)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(X_train, y_train, X_test, y_test, data_to_predict, max_features=10000, max_words=120, batch_size=128, epochs=4, num_classes=3):\n",
    "    \"\"\"\n",
    "    Documentation\n",
    "\n",
    "    Parameters:\n",
    "        max_features: the number of rows to take in input\n",
    "        max_words: the maximum amout of words that will be encoded for one row\n",
    "        batch_size: number of training examples utilized in one iteration\n",
    "        epochs: number of iterations\n",
    "        num_classes: number of labels to predict\n",
    "\n",
    "    Output:\n",
    "        y_pred5: prediction of y_test by the trained model\n",
    "    \"\"\"\n",
    "    model5_CNN = Sequential()\n",
    "    model5_CNN.add(Embedding(max_features, 100, input_length=max_words))\n",
    "    model5_CNN.add(Dropout(0.2))\n",
    "    model5_CNN.add(Conv1D(64, kernel_size=3, padding='same',\n",
    "                          activation='sigmoid', strides=1))\n",
    "    model5_CNN.add(GlobalMaxPooling1D())\n",
    "    model5_CNN.add(Dense(128, activation='sigmoid'))\n",
    "    model5_CNN.add(Dropout(0.4))\n",
    "    model5_CNN.add(Dense(num_classes, activation='softmax'))\n",
    "    model5_CNN.compile(loss='binary_crossentropy',\n",
    "                       optimizer='adam', metrics=['accuracy'])\n",
    "    model5_CNN.summary()\n",
    "    history5 = model5_CNN.fit(X_train, y_train, validation_data=(\n",
    "        X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "    y_pred = model5_CNN.predict_classes(data_to_predict, verbose=1)\n",
    "    return pd.Series(y_pred)-1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
